{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 一、tf.constant（常量声明）\n",
    "\n",
    "# 1.数值类型\n",
    "data = tf.constant([1,2])\n",
    "print(data)\n",
    "\n",
    "# 2.字符串类型\n",
    "data = tf.constant('hello')\n",
    "print(data)\n",
    "\n",
    "# 3.布尔类型\n",
    "#TensorFlow 的布尔类型和 Python 语言的布尔类型并不等价，不能通用\n",
    "data1 = tf.constant(True)\n",
    "data2 = True\n",
    "print(data1 == data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[0, 1, 2],\n",
      "       [2, 2, 2]])>\n"
     ]
    }
   ],
   "source": [
    "# 二、tf.Variable（变量声明）\n",
    "a1 = 7\n",
    "a2 = tf.Variable(a1)\n",
    "a3 = tf.Variable([[0,1,2],[2,2,2]])\n",
    "\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1107296256, shape=(), dtype=int32)\n",
      "tf.Tensor(1107296256.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# 三、tf.bitcast或tf.cast（改变数据类型）\n",
    "a = tf.constant(32.0)\n",
    "b = tf.bitcast(a,type=tf.int32)\n",
    "c = tf.cast(b,tf.float64)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n",
      "\n",
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(2, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[99 99]\n",
      " [99 99]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[2.0050347  2.1918166  2.1967683 ]\n",
      " [0.70630705 1.6620154  0.65952814]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "[[2.0050347  2.1918166  2.1967683 ]\n",
      " [0.70630705 1.6620154  0.65952814]]\n",
      "\n",
      "tf.Tensor(\n",
      "[[4 9 9]\n",
      " [6 4 9]], shape=(2, 3), dtype=int32)\n",
      "\n",
      "[[4 9 9]\n",
      " [6 4 9]]\n",
      "\n",
      "tf.Tensor([1 3 5 7 9], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 四、创建张量\n",
    "\n",
    "# 1.从列表创建张量\n",
    "print(tf.convert_to_tensor([1,2.,3]))\n",
    "print()\n",
    "\n",
    "# 2.从数组中创建张量\n",
    "print(tf.convert_to_tensor(np.array([[1,2.],[3,4]])))\n",
    "print()\n",
    "\n",
    "# 3.创建全0和全1的向量\n",
    "print(tf.zeros([2]))\n",
    "print(tf.ones([4]))\n",
    "print()\n",
    "\n",
    "# 4.创建全0和全1的矩阵\n",
    "print(tf.zeros([2,4]))\n",
    "print(tf.ones([3,2]))\n",
    "print()\n",
    "\n",
    "# 5.创建与张量a形状一样的全0张量：\n",
    "a = tf.ones([2,3]) # 创建一个矩阵\n",
    "print(tf.zeros_like(a)) # 创建一个与a形状相同，但是全0的新矩阵\n",
    "print()\n",
    "\n",
    "# 6.创建与张量a形状一样的全1张量：\n",
    "a = tf.zeros([2,3]) # 创建一个矩阵\n",
    "print(tf.ones_like(a)) # 创建一个与a形状相同，但是全1的新矩阵\n",
    "print()\n",
    "\n",
    "# 7.创建自定义数值张量\n",
    "print(tf.fill([2,2], 99)) #创建所有元素为99的矩阵\n",
    "print()\n",
    "\n",
    "# 8.创建已知分布的张量\n",
    "\n",
    "#8.1tf.random.normal（随机生成符合正态分布的Tensor）\n",
    "a = tf.random.normal(shape=[2,3],mean=2)\n",
    "print(a)\n",
    "print()\n",
    "print(a.numpy())\n",
    "print()\n",
    "\n",
    "#shape: 输出张量的形状，必选\n",
    "#mean: 正态分布的中心值即均值，默认为0\n",
    "#stddev: 正态分布的标准差，默认为1.0\n",
    "#dtype: 输出的类型，默认为tf.float32\n",
    "#seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样\n",
    "#name: 操作的名称\n",
    "\n",
    "#8.2tf.random.uniform（随机生成符合均匀分布的Tensor）\n",
    "a = tf.random.uniform(shape=[2,3],minval=1,maxval=10,seed=8,dtype=tf.int32)\n",
    "print(a)\n",
    "print()\n",
    "print(a.numpy())\n",
    "print()\n",
    "\n",
    "# 9.创建序列\n",
    "print( tf.range(1,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.50824964  0.4737508   0.6022392 ]\n",
      "  [-0.678725   -0.90917534 -1.8929946 ]\n",
      "  [-1.4360739   0.81102586  0.30779988]\n",
      "  [-0.7692204   0.30043572 -0.6317594 ]\n",
      "  [-0.88931555  0.771565   -0.3906411 ]\n",
      "  [-0.6804628  -1.3308413  -1.0551364 ]]\n",
      "\n",
      " [[ 0.8247307  -0.16783491 -2.3252935 ]\n",
      "  [-0.6526264   1.4084926   1.9640408 ]\n",
      "  [-0.5482488   0.76925004  0.80716306]\n",
      "  [-0.17672431 -1.7673584   0.36537415]\n",
      "  [-0.9724369  -0.19882043  0.6102701 ]\n",
      "  [-0.18393852  0.15106149  0.61718565]]\n",
      "\n",
      " [[ 0.8160369   2.761211   -0.1814909 ]\n",
      "  [-2.1020546  -0.07593818  0.4414888 ]\n",
      "  [ 1.1253241  -0.92563915  0.5294218 ]\n",
      "  [-0.6427986   0.01776238 -0.75979   ]\n",
      "  [ 2.2722716  -1.0058442  -0.9081826 ]\n",
      "  [-0.66184783 -1.9628239   1.7014719 ]]\n",
      "\n",
      " [[-0.38072243  0.08528593  1.7451619 ]\n",
      "  [-1.7675713  -0.25099733 -0.27552947]\n",
      "  [-1.3305908  -0.48720887 -0.36716932]\n",
      "  [-0.12220445 -0.17022449  0.0374745 ]\n",
      "  [ 0.22845414  1.6699435  -0.3000444 ]\n",
      "  [-0.31990975 -1.538705   -0.2709172 ]]\n",
      "\n",
      " [[-0.18877211 -0.12094232  0.24271683]\n",
      "  [-0.34877518  0.25346327  1.0476193 ]\n",
      "  [-1.4567888  -1.9847263  -1.3680512 ]\n",
      "  [ 0.108608    2.0530996   1.1920543 ]\n",
      "  [-1.0790803  -0.10332607 -2.0564082 ]\n",
      "  [-0.35851988  2.1751986   1.9562167 ]]\n",
      "\n",
      " [[-1.0872248  -0.08928626 -0.37688544]\n",
      "  [-1.12464    -1.8335407   0.1480748 ]\n",
      "  [-0.9265468   1.8691018  -1.9095455 ]\n",
      "  [-0.05083572  0.68731564  0.30819607]\n",
      "  [-0.8542408   0.84750783  1.122652  ]\n",
      "  [-1.2945724  -1.0580214  -0.369054  ]]], shape=(6, 6, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0.8247307  -0.16783491 -2.3252935 ]\n",
      " [-0.6526264   1.4084926   1.9640408 ]\n",
      " [-0.5482488   0.76925004  0.80716306]\n",
      " [-0.17672431 -1.7673584   0.36537415]\n",
      " [-0.9724369  -0.19882043  0.6102701 ]\n",
      " [-0.18393852  0.15106149  0.61718565]], shape=(6, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor([-0.5482488   0.76925004  0.80716306], shape=(3,), dtype=float32)\n",
      "\n",
      "tf.Tensor(0.414617, shape=(), dtype=float32)\n",
      "\n",
      "tf.Tensor([-1.0189676  -0.25187784 -0.928301  ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 五、索引与切片\n",
    "\n",
    "# 1.索引\n",
    "x = tf.random.normal([4,6,6,3]) # 创建4D张量\n",
    "\n",
    "#取第1张图片的数据\n",
    "print(x[0])\n",
    "print()\n",
    "\n",
    "#取第1张图片的第2行\n",
    "print(x[0][1])\n",
    "print()\n",
    "\n",
    "#取第1张图片的第2行第3列的数据\n",
    "print(x[0][1][2])\n",
    "print()\n",
    "\n",
    "#取第3张图片的第2行第1列的像素，B通道(第 2 个通道)颜色强度值\n",
    "print(x[2][1][0][1])\n",
    "print()\n",
    "\n",
    "#当张量的维度数较高时，使用[𝑖][𝑗]. . .[𝑘]的方式书写不方便，可以采用[𝑖,𝑗, … , 𝑘]的方式索引，它们是等价的。\n",
    "#取第2张图片，第2行，第3列的数据\n",
    "print(x[1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.50824964  0.4737508   0.6022392 ]\n",
      "   [-1.4360739   0.81102586  0.30779988]\n",
      "   [-0.88931555  0.771565   -0.3906411 ]]\n",
      "\n",
      "  [[ 0.8160369   2.761211   -0.1814909 ]\n",
      "   [ 1.1253241  -0.92563915  0.5294218 ]\n",
      "   [ 2.2722716  -1.0058442  -0.9081826 ]]\n",
      "\n",
      "  [[-0.18877211 -0.12094232  0.24271683]\n",
      "   [-1.4567888  -1.9847263  -1.3680512 ]\n",
      "   [-1.0790803  -0.10332607 -2.0564082 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.1095245  -1.5639743  -0.20459451]\n",
      "   [-0.8621914   0.02169924 -0.11253659]\n",
      "   [-0.8262552  -1.7213181   1.261009  ]]\n",
      "\n",
      "  [[ 0.28984308 -0.9332081  -1.5628093 ]\n",
      "   [-0.4239513   0.9956673  -0.19403884]\n",
      "   [-0.1388223   0.70321035 -1.4528259 ]]\n",
      "\n",
      "  [[-1.5224465   0.06760433 -0.7223576 ]\n",
      "   [-1.1672586  -0.89635473  0.04568629]\n",
      "   [-0.32735783 -1.4414088  -0.03732293]]]\n",
      "\n",
      "\n",
      " [[[-0.849695    0.05781463  0.07267959]\n",
      "   [ 1.3500048  -1.9250383  -0.3748379 ]\n",
      "   [ 0.8395184  -0.35256997  1.4800836 ]]\n",
      "\n",
      "  [[-1.4451728  -0.7591141  -0.46388584]\n",
      "   [ 1.366898   -0.2089776  -0.07395955]\n",
      "   [-0.5237021   0.5719624  -1.0809759 ]]\n",
      "\n",
      "  [[ 2.0859804   0.99460113  0.12104484]\n",
      "   [-1.6441982   2.0068452  -1.8962016 ]\n",
      "   [-0.3998853   0.5232087  -0.67190355]]]\n",
      "\n",
      "\n",
      " [[[ 1.7673627  -1.7514068  -0.32295156]\n",
      "   [ 0.30072322  1.1521013   0.67240286]\n",
      "   [-1.6719846  -0.6554475  -2.107283  ]]\n",
      "\n",
      "  [[-0.0038242   0.05621435 -0.071175  ]\n",
      "   [ 0.64832306  0.4274015   0.58208096]\n",
      "   [ 0.68383557  0.80128133  0.5826646 ]]\n",
      "\n",
      "  [[ 0.22476502  0.72864807 -0.39798325]\n",
      "   [-0.6086316  -0.7114005  -0.83195406]\n",
      "   [-0.39821288  0.59534854 -1.1161405 ]]]], shape=(4, 3, 3, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[[-1.2945724  -1.0580214  -0.369054  ]\n",
      "  [-0.05083572  0.68731564  0.30819607]\n",
      "  [-1.12464    -1.8335407   0.1480748 ]]\n",
      "\n",
      " [[-0.31990975 -1.538705   -0.2709172 ]\n",
      "  [-0.12220445 -0.17022449  0.0374745 ]\n",
      "  [-1.7675713  -0.25099733 -0.27552947]]\n",
      "\n",
      " [[-0.18393852  0.15106149  0.61718565]\n",
      "  [-0.17672431 -1.7673584   0.36537415]\n",
      "  [-0.6526264   1.4084926   1.9640408 ]]], shape=(3, 3, 3), dtype=float32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[[[-0.849695    0.05781463  0.07267959]\n",
      "   [ 0.1641095   0.917433    1.0031102 ]\n",
      "   [ 1.3500048  -1.9250383  -0.3748379 ]\n",
      "   [ 1.3385203  -0.7785538  -0.95133704]\n",
      "   [ 0.8395184  -0.35256997  1.4800836 ]\n",
      "   [-0.07277526 -1.1049782  -0.7114288 ]]\n",
      "\n",
      "  [[-0.6242587   0.414617   -1.3830911 ]\n",
      "   [ 1.8843291  -0.5856165  -0.57465124]\n",
      "   [-0.5754855  -0.43122855  0.14737934]\n",
      "   [ 0.983248   -0.2656865  -0.56386316]\n",
      "   [-0.37750214 -0.86524594 -0.5046713 ]\n",
      "   [ 0.01980595  0.7127373   0.8913648 ]]\n",
      "\n",
      "  [[-1.4451728  -0.7591141  -0.46388584]\n",
      "   [-1.0008717  -1.3338176  -1.0265487 ]\n",
      "   [ 1.366898   -0.2089776  -0.07395955]\n",
      "   [-0.3569658  -0.9134203   2.0020013 ]\n",
      "   [-0.5237021   0.5719624  -1.0809759 ]\n",
      "   [-1.3463397  -0.88226724 -1.4696091 ]]\n",
      "\n",
      "  [[ 1.3417712  -0.1308907   0.24865133]\n",
      "   [ 1.2589874  -1.357517   -0.36711383]\n",
      "   [ 1.0456455  -0.12580383  1.4637448 ]\n",
      "   [ 0.19596943 -0.594717   -1.4946523 ]\n",
      "   [-0.7395898   1.30794     0.12746547]\n",
      "   [ 0.7765859  -0.91703165  0.1696225 ]]\n",
      "\n",
      "  [[ 2.0859804   0.99460113  0.12104484]\n",
      "   [-0.6933459  -0.21189816 -1.4587667 ]\n",
      "   [-1.6441982   2.0068452  -1.8962016 ]\n",
      "   [-0.7390919   0.43085206 -0.03196619]\n",
      "   [-0.3998853   0.5232087  -0.67190355]\n",
      "   [-0.16048495 -1.0266985   0.10851119]]\n",
      "\n",
      "  [[-0.79384506 -0.8186526   0.6450389 ]\n",
      "   [ 0.46813333  0.26067582  0.04556689]\n",
      "   [ 0.98070866  0.77552456 -1.597934  ]\n",
      "   [-0.20106956  0.48512882  0.99569654]\n",
      "   [ 0.03133894  1.419479   -0.2601041 ]\n",
      "   [-0.6080932   0.3019935  -1.6280066 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.7673627  -1.7514068  -0.32295156]\n",
      "   [ 1.2159512   0.81692     0.5574606 ]\n",
      "   [ 0.30072322  1.1521013   0.67240286]\n",
      "   [ 0.26821032  1.1525103   1.4105554 ]\n",
      "   [-1.6719846  -0.6554475  -2.107283  ]\n",
      "   [ 1.023711    1.1448518   0.1102564 ]]\n",
      "\n",
      "  [[ 1.2893196   0.77157855 -1.1263857 ]\n",
      "   [ 0.20056155  0.42602366  0.30194703]\n",
      "   [-0.96325564 -2.0810685  -0.21463884]\n",
      "   [ 0.6960892   0.27354366  0.71513796]\n",
      "   [-0.0858857  -0.7778927   0.67515075]\n",
      "   [ 1.0925133   0.19269563 -0.24637513]]\n",
      "\n",
      "  [[-0.0038242   0.05621435 -0.071175  ]\n",
      "   [ 0.59535426  0.7219603  -0.4444038 ]\n",
      "   [ 0.64832306  0.4274015   0.58208096]\n",
      "   [-1.2851144  -0.20994848 -1.0805867 ]\n",
      "   [ 0.68383557  0.80128133  0.5826646 ]\n",
      "   [-0.15242925  0.54956347 -0.15558742]]\n",
      "\n",
      "  [[-1.298235    0.8000902  -0.11735416]\n",
      "   [-1.6980474   0.40551725  0.80983853]\n",
      "   [ 1.3931694  -1.6125928   1.3651845 ]\n",
      "   [-1.867909   -0.05930572 -0.9782985 ]\n",
      "   [ 0.27027497 -1.1608509   0.34661052]\n",
      "   [ 1.0263516  -0.5210151   0.9292674 ]]\n",
      "\n",
      "  [[ 0.22476502  0.72864807 -0.39798325]\n",
      "   [ 0.37612304  0.55053145  0.67383367]\n",
      "   [-0.6086316  -0.7114005  -0.83195406]\n",
      "   [-0.04033297 -0.21815045  1.6619031 ]\n",
      "   [-0.39821288  0.59534854 -1.1161405 ]\n",
      "   [ 0.9314239  -1.4863273   0.9915967 ]]\n",
      "\n",
      "  [[-2.5066977   0.48343784  0.8286256 ]\n",
      "   [ 1.2389162  -1.0764561   1.8974298 ]\n",
      "   [ 1.6767466  -0.8778125   0.55638903]\n",
      "   [-2.163698    1.4845897   0.26493204]\n",
      "   [-0.95292413  0.07052421 -0.7956013 ]\n",
      "   [ 1.0705187  -0.76462156 -0.27878425]]]], shape=(2, 6, 6, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2.切片(start: end: step)\n",
    "\n",
    "#读取所有图片、隔行采样、隔列采样、读取所有通道数据\n",
    "print( x[:,0:28:2,0:28:2,:])\n",
    "print()\n",
    "\n",
    "#行、列逆序间隔采样\n",
    "print(x[0,::-2,::-2])\n",
    "print()\n",
    "\n",
    "'''\n",
    "为了避免出现像 [: , : , : ,1]这样过多冒号的情况，可以使用⋯符号表示取多个维度上所\n",
    "有的数据\n",
    "'''\n",
    "#读取最后2张图片\n",
    "print(x[2:,...]) #高、宽、通道维度全部采集，等价于 x[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[0, 1, 2],\n",
      "       [4, 5, 6]])>\n",
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [2 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]], shape=(1, 3, 1), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]], shape=(2, 2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  4]\n",
      "  [ 2  5]\n",
      "  [ 3  6]]\n",
      "\n",
      " [[ 7 10]\n",
      "  [ 8 11]\n",
      "  [ 9 12]]], shape=(2, 3, 2), dtype=int32)\n",
      "\n",
      "[[[ 1  4]\n",
      "  [ 2  5]\n",
      "  [ 3  6]]\n",
      "\n",
      " [[ 7 10]\n",
      "  [ 8 11]\n",
      "  [ 9 12]]]\n"
     ]
    }
   ],
   "source": [
    "# 六、维度变换\n",
    "#1.tf.reshape （多阶Tensor形态变化）\n",
    "b1 = tf.Variable([[0,1,2],[4,5,6]])\n",
    "print(b1)\n",
    "\n",
    "b2 = tf.reshape(b1,[3,2])\n",
    "print(b2)\n",
    "print()\n",
    "\n",
    "#2.tf.expand_dims（增加维度）\n",
    "a = tf.constant([[1],[2],[3]])\n",
    "print(a)\n",
    "\n",
    "b = tf.expand_dims(a,0) #0是添加维度的下标，即最外层添加一个维度\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "#3.tf.squeeze（删除维度）\n",
    "c = tf.squeeze(b,0)\n",
    "print(c)\n",
    "print()\n",
    "\n",
    "#4.tf.transpose（交换维度）\n",
    "x = tf.constant([[[1, 2, 3],\n",
    "                  [4, 5, 6]],\n",
    "                 [[7, 8, 9],\n",
    "                 [10, 11, 12]]])\n",
    "print(x)\n",
    "a = tf.transpose(x,perm=[0,2,1]) #0–代表的是最外层的一维, 1–代表外向内数第二维, 2–代表最内层的一维\n",
    "print(a) #2*2*3变为2*3*2\n",
    "print()\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2]], shape=(1, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n",
      "\n",
      "a\n",
      "tf.Tensor(\n",
      "[[[-1.7365359  -0.579554    0.90367764]\n",
      "  [-0.08709873  1.3670171   0.33483225]\n",
      "  [ 1.1239908  -2.5393217  -0.73685807]\n",
      "  [ 0.6100827  -0.40933266 -1.8553503 ]]\n",
      "\n",
      " [[-0.9365184   1.8084974   0.54663575]\n",
      "  [ 0.47172767 -2.0992267   2.005945  ]\n",
      "  [ 0.01743619 -0.5021706   0.7816504 ]\n",
      "  [ 0.42757702  0.6989862   0.30794623]]], shape=(2, 4, 3), dtype=float32)\n",
      "b\n",
      "tf.Tensor(\n",
      "[[-1.7400575  -0.37973708  0.93470067]\n",
      " [-0.41487893 -0.8283052  -0.5473837 ]\n",
      " [ 1.0384055   1.5220569   0.4423968 ]\n",
      " [-2.4395819  -0.5547633   0.43775272]], shape=(4, 3), dtype=float32)\n",
      "a+b\n",
      "tf.Tensor(\n",
      "[[[-3.4765935  -0.9592911   1.8383783 ]\n",
      "  [-0.5019777   0.53871197 -0.21255147]\n",
      "  [ 2.1623964  -1.0172647  -0.29446128]\n",
      "  [-1.8294992  -0.96409595 -1.4175975 ]]\n",
      "\n",
      " [[-2.676576    1.4287603   1.4813364 ]\n",
      "  [ 0.05684873 -2.927532    1.4585612 ]\n",
      "  [ 1.0558417   1.0198863   1.2240472 ]\n",
      "  [-2.0120049   0.14422286  0.7456989 ]]], shape=(2, 4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 七、复制数据\n",
    "\n",
    "# 1.tf.tile(x, multiples)\n",
    "#，multiples 分别指定了每个维度上面的复制倍数，对应位置为 1 表明不复制，为 2 表明新长度为原来长度的2 倍\n",
    "b = tf.constant([1,2]) #创建向量b\n",
    "b = tf.expand_dims(b, axis=0) # 插入新维度，变成矩阵\n",
    "print(b)\n",
    "b = tf.tile(b, multiples=[2,1])\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "# 2.Broadcasting(广播机制)\n",
    "a = tf.random.normal([2,4,3])\n",
    "b = tf.random.normal([4,3])\n",
    "print('a')\n",
    "print(a)\n",
    "print('b')\n",
    "print(b)\n",
    "print('a+b') #操作符+在遇到shape不一致的 2 个张量时，会自动考虑将2个张量自动扩展到一致的shape，然后再调用tf.add完成张量相加运算\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor([2 3 4 5 6], shape=(5,), dtype=int32)\n",
      "tf.Tensor([-2 -1  0  1  2], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0.  0.5 1.  1.5 2. ], shape=(5,), dtype=float64)\n",
      "tf.Tensor([0 0 1 1 2], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0 1 0 1 0], shape=(5,), dtype=int32)\n",
      "\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 0  1  8 27], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 1 4 9], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0. 1. 4. 9.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 1. 2. 3.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 八、数学运算\n",
    "\n",
    "# 1.加、减、乘、除运算\n",
    "a = tf.range(5)\n",
    "b = tf.constant(2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "print(a//b) # 整除运算\n",
    "print(a%b) # 余除运算\n",
    "print()\n",
    "\n",
    "# 2.乘方运算\n",
    "x = tf.range(4)\n",
    "print(x)\n",
    "print(tf.pow(x,3)) # 乘方运算\n",
    "print(x**2) #乘方运算符\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "x = tf.square(x)\n",
    "print(x) #平方\n",
    "print(tf.sqrt(x)) #平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
